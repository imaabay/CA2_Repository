{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN7cDsdh9iQC3CNSGSNABA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eba2a934927c41129eb1a4895a63f946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a54a12957a8a461bba751ca3def5b37a",
              "IPY_MODEL_20993b32ed014a7b95a4328a6bb5c7a1",
              "IPY_MODEL_29ea9029bebd4b72812257170b843215"
            ],
            "layout": "IPY_MODEL_1c8c178c7888433ab995837b07073400"
          }
        },
        "a54a12957a8a461bba751ca3def5b37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e43570bde441e89f4bf01cb09ef51b",
            "placeholder": "​",
            "style": "IPY_MODEL_d08e4079d2314b28a85556b38e5dcf9c",
            "value": ""
          }
        },
        "20993b32ed014a7b95a4328a6bb5c7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb3a2e72448431e80726215e3daaa3f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be6c1c3a50304e8f8dd2287fd36beb4e",
            "value": 1
          }
        },
        "29ea9029bebd4b72812257170b843215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8bf4be700bd49a8b41bac1e8bb53e9e",
            "placeholder": "​",
            "style": "IPY_MODEL_85c27d228d0440f387ba6933d8a0b76b",
            "value": " 3/? [00:18&lt;00:00,  7.47s/it]"
          }
        },
        "1c8c178c7888433ab995837b07073400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e43570bde441e89f4bf01cb09ef51b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08e4079d2314b28a85556b38e5dcf9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddb3a2e72448431e80726215e3daaa3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "be6c1c3a50304e8f8dd2287fd36beb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8bf4be700bd49a8b41bac1e8bb53e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85c27d228d0440f387ba6933d8a0b76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imaabay/CA2_Repository/blob/main/method2/gpt_experiments/ST02A_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc3rbHyCPyMC",
        "outputId": "24d1de6b-c56c-48a5-85e4-c64f9c25625a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.54.4)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.9-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.11-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain-core, langchain-openai, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.9 langchain-community-0.3.9 langchain-core-0.3.21 langchain-openai-0.2.11 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI, ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "v20NHPvDXBp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")"
      ],
      "metadata": {
        "id": "-qA7DeKbXTrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Evaluation Metrics"
      ],
      "metadata": {
        "id": "flLnbNmXXf5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI # Try ChatAnthropic as well\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langsmith.evaluation import LangChainStringEvaluator\n",
        "\n",
        "_PROMPT_TEMPLATE = \"\"\"\n",
        "  You are an expert tasked with evaluating the explainability of large language model-generated answers for medical diagnoses.\n",
        "  Your role is to assess whether the given answers provide sufficient explanation and clarity for a user to understand the medical diagnosis.\n",
        "  You are assessing the following question:\n",
        "  {query}\n",
        "  Here is the real answer:\n",
        "  {context}\n",
        "  You are assessing the following predicted answer:\n",
        "  {result}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables = [\"query\", \"context\", \"result\"],\n",
        "    template = _PROMPT_TEMPLATE\n",
        ")\n",
        "\n",
        "eval_llm = ChatOpenAI( temperature=0)\n",
        "\n",
        "evaluators = [\n",
        "  LangChainStringEvaluator(\"context_qa\", config={\"llm\": eval_llm, \"prompt\": PROMPT}),\n",
        "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"conciseness\"}),\n",
        "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"coherence\"}),\n",
        "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"detail\"}),\n",
        "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"helpfulness\"}),\n",
        "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"depth\"}),\n",
        "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"insensitivity\"}),\n",
        "  LangChainStringEvaluator(\"labeled_criteria\", config={\"criteria\": \"harmfulness\"}),\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "50_I0M1tXiOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Templates"
      ],
      "metadata": {
        "id": "KjdJQO_WKzpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_1 = \"\"\"\n",
        "You are an AI chatbot designed to assist doctors in diagnosing patients using causal and counterfactual reasoning methods. Your\n",
        "    role is to provide accurate diagnoses based on the information provided.\n",
        "\n",
        "    Reason through this step by step based on the following:\n",
        "      1. Analyse the underlying causes of symptoms while also exploring counterfactuals- what might have occurred\n",
        "        under different circumstances or the absence of certain symptoms.\n",
        "      2. Clearly explain the reasoning behind each diagnosis, highliting cause-and-effect relationships and any relevant\n",
        "        counterfactual scenarios.\n",
        "      3. For the final diagnosis, present the one that has the highest probability and including the reasoning.\n",
        "\n",
        "Always ensure that the information you provide is truthful, reliable, and based on established medical knowledge.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nBs0hsiFKzOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_2 = \"\"\"\n",
        "    You are an AI assistant designed to help doctors diagnose patients using causal and counterfactual reasoning methods. Your role\n",
        "    is to provide accurate diagnoses based on the information provided, following these steps:\n",
        "    1. Analyse the symptoms:\n",
        "      a. List the patient's symptoms and relevant medical history\n",
        "      b. Identify potential underlying causes for each symptom.\n",
        "      c. Consider how these symptoms might interact or influence each other.\n",
        "    2. Explore causal relationships:\n",
        "      a. Create a simple causal graph showing how symptoms and potential causes might be linked.\n",
        "    3. Consider counterfactuals:\n",
        "      a. Analyse the underlying causes of symptoms while also exploring counterfactuals- what might have occurred\n",
        "        under different circumstances or the absence of certain symptoms.\n",
        "    4. Develop potential diagnoses:\n",
        "      a. Based on the causal analysis and counterfactual reasoning, list possible diagnoses.\n",
        "      b. For each diagnosis, explain why it fits the symptoms and causal relationships observed.\n",
        "    5. Present the most likely diagnosis:\n",
        "      a. Identify the diagnosis with the highest probability.\n",
        "      b. Clearly explain why this diagnosis is most likely, referring back to the causal relationships and counterfactual scenarios discussed earlier.\n",
        "    6. Suggest next steps:\n",
        "      a. Recommend any additional tests or examinations that could confirm or rule out the diagnosis.\n",
        "      b. If applicable, suggest potential treatment options, explaining how they address the causal factors identified.\n",
        "\n",
        "    Remember to always base your analysis on established medical knowledge and current best practices. If there's any uncertainty or if multiple diagnoses seem equally likely, clearly state this and explain why further investigation might be needed\n",
        "\n",
        "    Reason through this step by step. Please present this in a manner which is clear and clean, use different titles and subtitles.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qOgYUQzhK9S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_3 = \"\"\"\n",
        "   You are an AI chatbot designed to help doctors in diagnosing patients. Your\n",
        "    role is to provide accurate diagnoses based on the information provided,\n",
        "    following Pearl's three-layer causal hierarchy.\n",
        "\n",
        "    Reason through this step by step:\n",
        "\n",
        "    1. Association (Level 1):\n",
        "     a. What symptoms does the patient present?\n",
        "     b. What conditions are commonly associated with these symptoms?\n",
        "     c. What is the likelihood of each potential diagnosis given the symptoms?\n",
        "\n",
        "    2. Intervention (Level 2):\n",
        "     a. What diagnostic tests or interventions would you reccomend to confirm or rule\n",
        "       out potential diagnoses?\n",
        "     b. How would the results of these tests affect the likelihood of each diagnoses?\n",
        "     c. What treatments would you consider, and how might they impact the patient's condition.\n",
        "\n",
        "    3. Counterfactuals (Level 3):\n",
        "     a. If a certain symptom were absent, how would that change the diagnosis?\n",
        "     b. What if the patient has risk factors?\n",
        "     c. How would the outcome differ if an alternative treatment were chosen?\n",
        "\n",
        "   Always ensure that the information you provide is truthful, reliable, and based on established medical knowledge.\n",
        "   Explain your reasoning at each step to make the diagnosis process more transparent and explainable.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BlvrTSvzyHOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Evaluation"
      ],
      "metadata": {
        "id": "sVG8OUZkKsfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai_client = openai.Client()\n",
        "\n",
        "def my_app_v1(question):\n",
        "   return openai_client.chat.completions.create(\n",
        "       model=\"gpt-4o-mini\",\n",
        "       temperature=0,\n",
        "       messages=[\n",
        "           {\n",
        "               \"role\": \"system\",\n",
        "               \"content\": template_3,\n",
        "           },\n",
        "           {\n",
        "               \"role\": \"user\",\n",
        "               \"content\": question,\n",
        "           }\n",
        "       ],\n",
        "   ).choices[0].message.content\n",
        "\n",
        "def langsmith_app(inputs):\n",
        "  output = my_app_v1(inputs[\"question\"])\n",
        "  return {\"output\": output}"
      ],
      "metadata": {
        "id": "tuDGA594XlmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import evaluate\n",
        "\n",
        "experiment_results = evaluate(\n",
        "    langsmith_app, # AI System\n",
        "    data = \"XAI_EVAL\",\n",
        "    evaluators=evaluators,\n",
        "    experiment_prefix=\"causal-ai-template3-evaluation-gpt-4o-mini\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eba2a934927c41129eb1a4895a63f946",
            "a54a12957a8a461bba751ca3def5b37a",
            "20993b32ed014a7b95a4328a6bb5c7a1",
            "29ea9029bebd4b72812257170b843215",
            "1c8c178c7888433ab995837b07073400",
            "22e43570bde441e89f4bf01cb09ef51b",
            "d08e4079d2314b28a85556b38e5dcf9c",
            "ddb3a2e72448431e80726215e3daaa3f",
            "be6c1c3a50304e8f8dd2287fd36beb4e",
            "e8bf4be700bd49a8b41bac1e8bb53e9e",
            "85c27d228d0440f387ba6933d8a0b76b"
          ]
        },
        "id": "Kdfd1dkeLhnv",
        "outputId": "fa7dcf6e-0f12-4c18-b3d7-accbf9b37fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for experiment: 'causal-ai-template3-evaluation-gpt-4o-mini-7e8b526f' at:\n",
            "https://smith.langchain.com/o/683c5cb9-3b64-5127-a5a8-405b032642f2/datasets/b7b8dceb-8703-42f2-92ba-cfa8aad7542b/compare?selectedSessions=8017ef0d-c71f-44e7-959d-833c951f53ed\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eba2a934927c41129eb1a4895a63f946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1629, in _forward\n",
            "    fn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 22, in langsmith_app\n",
            "    output = my_app_v1(inputs[\"question\"])\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 6, in my_app_v1\n",
            "    return openai_client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1629, in _forward\n",
            "    fn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 22, in langsmith_app\n",
            "    output = my_app_v1(inputs[\"question\"])\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 6, in my_app_v1\n",
            "    return openai_client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1629, in _forward\n",
            "    fn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 22, in langsmith_app\n",
            "    output = my_app_v1(inputs[\"question\"])\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 6, in my_app_v1\n",
            "    return openai_client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1629, in _forward\n",
            "    fn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 22, in langsmith_app\n",
            "    output = my_app_v1(inputs[\"question\"])\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 6, in my_app_v1\n",
            "    return openai_client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1629, in _forward\n",
            "    fn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 22, in langsmith_app\n",
            "    output = my_app_v1(inputs[\"question\"])\n",
            "  File \"<ipython-input-6-3bf539279eca>\", line 6, in my_app_v1\n",
            "    return openai_client.chat.completions.create(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 1ad99c54-e421-4b2d-b1fc-6a7c67a8c5c5: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 306, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run c535c862-c408-4b53-be29-8ccb87018bca: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 306, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 86102bb8-083a-4e86-9f04-8a2e704b754b: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 306, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b74ff175-9ad6-47ca-839e-f680092ef3e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 306, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 42a039be-53f7-47f7-bced-873e2358bb46: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/qa/eval_chain.py\", line 306, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run c535c862-c408-4b53-be29-8ccb87018bca: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 1ad99c54-e421-4b2d-b1fc-6a7c67a8c5c5: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 42a039be-53f7-47f7-bced-873e2358bb46: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 86102bb8-083a-4e86-9f04-8a2e704b754b: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b74ff175-9ad6-47ca-839e-f680092ef3e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run c535c862-c408-4b53-be29-8ccb87018bca: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 1ad99c54-e421-4b2d-b1fc-6a7c67a8c5c5: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 42a039be-53f7-47f7-bced-873e2358bb46: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b74ff175-9ad6-47ca-839e-f680092ef3e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 86102bb8-083a-4e86-9f04-8a2e704b754b: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run c535c862-c408-4b53-be29-8ccb87018bca: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 1ad99c54-e421-4b2d-b1fc-6a7c67a8c5c5: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 42a039be-53f7-47f7-bced-873e2358bb46: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b74ff175-9ad6-47ca-839e-f680092ef3e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 86102bb8-083a-4e86-9f04-8a2e704b754b: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run c535c862-c408-4b53-be29-8ccb87018bca: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 1ad99c54-e421-4b2d-b1fc-6a7c67a8c5c5: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b74ff175-9ad6-47ca-839e-f680092ef3e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 42a039be-53f7-47f7-bced-873e2358bb46: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 86102bb8-083a-4e86-9f04-8a2e704b754b: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 1ad99c54-e421-4b2d-b1fc-6a7c67a8c5c5: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run c535c862-c408-4b53-be29-8ccb87018bca: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b74ff175-9ad6-47ca-839e-f680092ef3e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 42a039be-53f7-47f7-bced-873e2358bb46: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 86102bb8-083a-4e86-9f04-8a2e704b754b: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run c535c862-c408-4b53-be29-8ccb87018bca: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 1ad99c54-e421-4b2d-b1fc-6a7c67a8c5c5: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b74ff175-9ad6-47ca-839e-f680092ef3e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 42a039be-53f7-47f7-bced-873e2358bb46: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 86102bb8-083a-4e86-9f04-8a2e704b754b: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run c535c862-c408-4b53-be29-8ccb87018bca: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 1ad99c54-e421-4b2d-b1fc-6a7c67a8c5c5: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run b74ff175-9ad6-47ca-839e-f680092ef3e1: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 42a039be-53f7-47f7-bced-873e2358bb46: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator evaluate> on run 86102bb8-083a-4e86-9f04-8a2e704b754b: RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\", line 1384, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/evaluator.py\", line 329, in evaluate_run\n",
            "    result = self.func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/run_helpers.py\", line 611, in wrapper\n",
            "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/integrations/_langchain.py\", line 260, in evaluate\n",
            "    results = self.evaluator.evaluate_strings(**eval_inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/schema.py\", line 220, in evaluate_strings\n",
            "    return self._evaluate_strings(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/evaluation/criteria/eval_chain.py\", line 446, in _evaluate_strings\n",
            "    result = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\", line 182, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 389, in __call__\n",
            "    return self.invoke(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 170, in invoke\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\", line 160, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 126, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\", line 138, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 829, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1278, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 955, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1044, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1093, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1059, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d0e203b4d5d7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangsmith\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m experiment_results = evaluate(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlangsmith_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# AI System\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"XAI_EVAL\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;34mf\"Got: experiment={experiment}, experiment_prefix={experiment_prefix}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         )\n\u001b[0;32m--> 287\u001b[0;31m     return _evaluate(\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_summary_evaluators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_evaluators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;31m# Start consuming the results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperimentResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, experiment_manager, blocking)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mtqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mExperimentResultRow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;34m\"\"\"Return the traces, evaluation results, and associated examples.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         for run, example, evaluation_results in zip(\n\u001b[0m\u001b[1;32m   1303\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         ):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mruns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0mevaluation_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"evaluation_results\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0msummary_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langsmith/evaluation/_runner.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, evaluators, max_concurrency)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    243\u001b[0m                             len(pending), total_futures))\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}